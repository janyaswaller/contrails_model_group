{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lightning Workflow for Contrails","metadata":{}},{"cell_type":"markdown","source":"### Notebook to run models based on single bands / band combinations","metadata":{}},{"cell_type":"code","source":"!pip install lightning -q","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:50:07.679843Z","iopub.execute_input":"2023-07-17T09:50:07.680132Z","iopub.status.idle":"2023-07-17T09:50:26.612172Z","shell.execute_reply.started":"2023-07-17T09:50:07.680097Z","shell.execute_reply":"2023-07-17T09:50:26.610889Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# lightning library\nimport lightning as L\nfrom lightning import LightningDataModule, LightningModule, Trainer\nfrom lightning.pytorch.callbacks.progress import TQDMProgressBar\nfrom lightning.pytorch.loggers import CSVLogger, TensorBoardLogger\n\n\n# pytorch libraries\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import transforms\nfrom torchmetrics.classification import Dice\nfrom torchmetrics import Precision, Recall, Accuracy\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import CSVLogger\n\n\n# other\nimport os\nimport subprocess\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display\nfrom PIL import Image\n\n# set base directory\nBASE_DIR = \"/kaggle/input/google-research-identify-contrails-reduce-global-warming\"\n\n# set batch size\nBATCH_SIZE = 16 if torch.cuda.is_available() else 8\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-17T09:50:26.617876Z","iopub.execute_input":"2023-07-17T09:50:26.618224Z","iopub.status.idle":"2023-07-17T09:50:41.624063Z","shell.execute_reply.started":"2023-07-17T09:50:26.618193Z","shell.execute_reply":"2023-07-17T09:50:41.623056Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n/tmp/ipykernel_28/501820186.py:27: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n  from IPython.core.display import display\n","output_type":"stream"}]},{"cell_type":"code","source":"# GPU available?\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:50:41.625635Z","iopub.execute_input":"2023-07-17T09:50:41.626312Z","iopub.status.idle":"2023-07-17T09:50:41.636330Z","shell.execute_reply.started":"2023-07-17T09:50:41.626278Z","shell.execute_reply":"2023-07-17T09:50:41.635457Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# List all examples from the train / val / test directories\ntrain_list = os.listdir(BASE_DIR + '/train/')\nval_list = os.listdir(BASE_DIR + '/validation/')\ntest_list = os.listdir(BASE_DIR + '/test/')\n\nprint(f\"number of traning examples: {len(train_list)}\")\nprint(f\"number of validation examples: {len(val_list)}\")\nprint(f\"number of test examples: {len(test_list)}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:50:52.234516Z","iopub.execute_input":"2023-07-17T09:50:52.234915Z","iopub.status.idle":"2023-07-17T09:50:52.710887Z","shell.execute_reply.started":"2023-07-17T09:50:52.234883Z","shell.execute_reply":"2023-07-17T09:50:52.709928Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"number of traning examples: 20529\nnumber of validation examples: 1856\nnumber of test examples: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# see files for an arbitrary training example\nband_list = os.listdir(BASE_DIR + '/train/' + train_list[0])\n#band_list = [band for band in band_list if band.startswith(\"band_\")]\nprint(band_list)\nprint(np.load(BASE_DIR + '/train/' + train_list[0] + '/band_10.npy').shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:50:54.556513Z","iopub.execute_input":"2023-07-17T09:50:54.556915Z","iopub.status.idle":"2023-07-17T09:50:54.631437Z","shell.execute_reply.started":"2023-07-17T09:50:54.556886Z","shell.execute_reply":"2023-07-17T09:50:54.630459Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['band_10.npy', 'band_14.npy', 'human_individual_masks.npy', 'band_15.npy', 'band_16.npy', 'band_08.npy', 'band_09.npy', 'band_13.npy', 'band_11.npy', 'human_pixel_masks.npy', 'band_12.npy']\n(256, 256, 8)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preparing to standardize the data","metadata":{}},{"cell_type":"markdown","source":"\"Each input channel is standardized by subtracting the global mean and dividing by the global variance of the channel before feeding it into the network\" (Joe et al., 2023).","metadata":{}},{"cell_type":"code","source":"# creating a list of channels -i.e. \"bands\" (without targets)\nband_list = [band for band in band_list if band.startswith(\"band_\")]\n\n# create empty dicts to store band-specific global mean and std\nmean_list = {}\nstd_list = {}\n\n# calculate global means and stds to normalize the data before training\nfor n_channel, channel in enumerate(band_list):\n    channel_data = []\n    \n    for band in band_list:\n        band_data = []\n    \n        for train_example in train_list[:300]:\n            example_data = np.load(BASE_DIR + '/train/' + train_list[n_channel] + '/' + band).flatten()\n        \n        band_data.append(example_data)\n    \n    channel_data.append(np.concatenate(band_data))  \n    mean_list[channel] = np.mean(channel_data)\n    std_list[channel] = np.std(channel_data)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:50:56.472450Z","iopub.execute_input":"2023-07-17T09:50:56.473129Z","iopub.status.idle":"2023-07-17T09:51:33.394371Z","shell.execute_reply.started":"2023-07-17T09:50:56.473083Z","shell.execute_reply":"2023-07-17T09:51:33.393321Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print([mean_list.get(x) for x in [\"band_10.npy\", \"band_11.npy\"]])\nprint(std_list.values())","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:51:33.396375Z","iopub.execute_input":"2023-07-17T09:51:33.397108Z","iopub.status.idle":"2023-07-17T09:51:33.402956Z","shell.execute_reply.started":"2023-07-17T09:51:33.397063Z","shell.execute_reply":"2023-07-17T09:51:33.401839Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[257.98895, 255.35904]\ndict_values([11.159583, 15.506918, 10.20968, 3.221322, 6.7606144, 8.125894, 5.7324905, 5.8463006, 10.416265])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Creating the Dataloader","metadata":{}},{"cell_type":"code","source":"class ContrailsDataset(torch.utils.data.Dataset):\n    def __init__(self, filepath, transform=None, bands=[\"band_08.npy\"], timestep=4):\n        self.filepath = filepath\n        self.transform = transform\n        self.bands = bands\n        self.timestep = timestep\n\n        # List of file names in the image and target directories\n        self.examples = os.listdir(self.filepath)\n\n    def __len__(self):\n        return len(self.examples)  # assuming images and targets have a 1-1 correspondence\n\n    def __getitem__(self, idx):\n        #if torch.is_tensor(idx):\n        #    idx = idx.tolist()\n\n        img_name = os.path.join(self.filepath, self.examples[idx])\n        target_name = os.path.join(self.filepath, self.examples[idx])\n        \n        #if len(self.bands) == 1:\n        #    image = np.load(os.path.join(img_name, self.bands[0]))[:,:,self.timestep]\n            \n        #if len(self.bands) > 1:\n        band_channels = []\n        for _, b in enumerate(self.bands):\n            image = np.load(os.path.join(img_name, b))[:,:,self.timestep]\n            band_channels.append(image)\n        image = np.dstack([b for b in band_channels])\n        #image = image.transpose( 2, 0, 1)\n        #image = torch.tensor(image)\n        \n        targets = np.load(os.path.join(target_name, \"human_pixel_masks.npy\"))\n        targets = targets[..., -1]\n        targets = torch.tensor(targets).to(torch.long)\n        #image = torch.tensor(np.reshape(image, (256, 256, 1))).to(torch.float32).permute(2, 0, 1)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, targets\n","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:08.515727Z","iopub.execute_input":"2023-07-17T09:52:08.516724Z","iopub.status.idle":"2023-07-17T09:52:08.527597Z","shell.execute_reply.started":"2023-07-17T09:52:08.516684Z","shell.execute_reply":"2023-07-17T09:52:08.526243Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### ...testing the dataloader:","metadata":{}},{"cell_type":"code","source":"bands = [\"band_11.npy\"]\n# Transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize([mean_list.get(x) for x in bands],\n                         [std_list.get(x) for x in bands]), #using the precomputed values\n])","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:11.409625Z","iopub.execute_input":"2023-07-17T09:52:11.410585Z","iopub.status.idle":"2023-07-17T09:52:11.417504Z","shell.execute_reply.started":"2023-07-17T09:52:11.410553Z","shell.execute_reply":"2023-07-17T09:52:11.416274Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create your datasets\ntrain_dataset = ContrailsDataset(\n    filepath= BASE_DIR + '/train/', \n    transform=transform,\n    bands=list([\"band_08.npy\"])\n)\n\nval_dataset = ContrailsDataset(\n    filepath= BASE_DIR + '/validation/', \n    transform=transform,\n)\n\ntest_dataset = ContrailsDataset(\n    filepath= BASE_DIR + '/test/', \n    transform=transform,\n)\n\n# Create your dataloaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:12.394477Z","iopub.execute_input":"2023-07-17T09:52:12.394859Z","iopub.status.idle":"2023-07-17T09:52:12.412837Z","shell.execute_reply.started":"2023-07-17T09:52:12.394828Z","shell.execute_reply":"2023-07-17T09:52:12.411927Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# load one batch of images and labels\ndataiter = iter(train_dataloader)\nimages, targets = next(dataiter)\n\n# check shapes of the batch\nimages = torch.tensor(images).flatten(start_dim=2)\nprint(images.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T06:20:47.614467Z","iopub.execute_input":"2023-07-17T06:20:47.614849Z","iopub.status.idle":"2023-07-17T06:20:48.558239Z","shell.execute_reply.started":"2023-07-17T06:20:47.614820Z","shell.execute_reply":"2023-07-17T06:20:48.557207Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"torch.Size([16, 1, 65536])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_28/3019820314.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  images = torch.tensor(images).flatten(start_dim=2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# load one batch of images and labels\ndataiter = iter(train_dataloader)\nimages, targets = next(dataiter)\n\n# check shapes of the batch\nprint(images.shape)\nprint(targets.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T05:44:55.981143Z","iopub.execute_input":"2023-07-17T05:44:55.981535Z","iopub.status.idle":"2023-07-17T05:44:56.605435Z","shell.execute_reply.started":"2023-07-17T05:44:55.981502Z","shell.execute_reply":"2023-07-17T05:44:56.604426Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"torch.Size([16, 1, 256, 256])\ntorch.Size([16, 256, 256])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Lightning Data Module","metadata":{}},{"cell_type":"code","source":"class ContrailsDataModule(L.LightningDataModule):\n    def __init__(\n        self,\n        data_dir: str = BASE_DIR,\n        batch_size: int = BATCH_SIZE,\n        bands: list = bands,\n        timestep: int = 4,\n    ):\n    \n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.bands = bands\n        self.timestep = timestep\n        \n        # Transformations\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([mean_list.get(x) for x in self.bands],\n                                 [std_list.get(x) for x in self.bands]), #using the precomputed values\n        ])\n\n        \n        self.dims = (len(self.bands), 256, 256)\n        \n    def prepare_data(self):\n        pass\n\n    def setup(self, stage=None):\n        # Assign train/val datasets for use in dataloaders\n        if stage == \"fit\" or stage is None:\n\n            self.train_dataset = ContrailsDataset(\n                filepath= self.data_dir + '/train/', \n                transform=self.transform,\n                bands=self.bands,\n                timestep=self.timestep,\n                )\n            \n            self.val_dataset = ContrailsDataset(\n                filepath= self.data_dir + '/validation/', \n                transform=self.transform,\n                bands=self.bands,\n                )\n\n        \n        # Assign test dataset for use in dataloader(s)\n        if stage == \"test\" or stage is None:\n            \n                self.test_dataset = ContrailsDataset(\n                filepath= self.data_dir + '/test/', \n                transform=self.transform,\n                bands=self.bands,\n                )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n        )\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, \n                          batch_size=self.batch_size, \n                          shuffle=False,\n                         )\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset,\n                         shuffle=False)\n\n    #def test_dataloader(self):\n    #    return DataLoader(self.mnist_test, batch_size=self.batch_size, bands=list([\"band_12\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:16.346630Z","iopub.execute_input":"2023-07-17T09:52:16.347322Z","iopub.status.idle":"2023-07-17T09:52:16.359680Z","shell.execute_reply.started":"2023-07-17T09:52:16.347289Z","shell.execute_reply":"2023-07-17T09:52:16.358640Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Implement the U-Net Model from https://paperswithcode.com/method/u-net","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n\n        # if bilinear, use the normal convolutions to reduce the number of channels\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        # input is CHW\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2])\n        # if you have padding issues, see\n        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n        x = torch.cat([x2, x1], dim=1)\n        return self.conv(x)\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n    def forward(self, x):\n        return self.conv(x)\n    \nclass UNet2(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True):\n        super(UNet2, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:18.756446Z","iopub.execute_input":"2023-07-17T09:52:18.756894Z","iopub.status.idle":"2023-07-17T09:52:18.780327Z","shell.execute_reply.started":"2023-07-17T09:52:18.756864Z","shell.execute_reply":"2023-07-17T09:52:18.779270Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class U_Net(nn.Module):\n    def __init__(self, n_channels, n_classes, bilinear=True, lr=0.001):\n        super(UNet2, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        self.learning_rate = lr\n        \n        # counter and accumulator for progress\n        self.counter = 0\n        self.progress = []\n        \n        # loss\n        self.loss_function = nn.CrossEntropyLoss()\n        \n        # optimizer\n        self.optimiser = torch.optim.Adam(self.parameters(), lr=learning_rate)\n\n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512, 1024 // factor)\n        self.up1 = Up(1024, 512 // factor, bilinear)\n        self.up2 = Up(512, 256 // factor, bilinear)\n        self.up3 = Up(256, 128 // factor, bilinear)\n        self.up4 = Up(128, 64, bilinear)\n        self.outc = OutConv(64, n_classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        logits = self.outc(x)\n        return logits\n    \n    def train(self, input, target):\n        pred = self(input)\n        loss = self.loss(pred, target)\n        \n        # increase counter and accumulate error every 10\n        self.counter += 1\n        if (self.counter % 10 == 0):\n            self.progress.append(loss.item())\n            pass\n        if (self.counter % 1000 == 0):\n            print(\"counter = \", self.counter)\n            pass\n        \n        # zero gradients, perform a backward pass, and update the weights\n        self.optimiser.zero_grad()\n        loss.backward()\n        self.optimiser.step()\n        \n        \n    def plot_progress(self):\n        df = pd.DataFrame(self.progress, columns=['loss'])\n        df.plot(ylim=(0, 1.0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5))","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:19.964515Z","iopub.execute_input":"2023-07-17T09:52:19.964904Z","iopub.status.idle":"2023-07-17T09:52:19.980249Z","shell.execute_reply.started":"2023-07-17T09:52:19.964875Z","shell.execute_reply":"2023-07-17T09:52:19.979072Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Creating the Lightning Module for training","metadata":{}},{"cell_type":"code","source":"class Contrails_U_Net(L.LightningModule):\n    def __init__(self, learning_rate=1e-5, n_channels = 1, n_classes = 2):\n        super().__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.model = UNet2(self.n_channels, self.n_classes)\n        self.CEL = nn.CrossEntropyLoss(weight = torch.Tensor([0.57, 4.17]))\n        self.learning_rate = learning_rate\n        \n        self.precision = Precision(task=\"binary\", average='macro', num_classes=2) # binary classification \n        self.recall = Recall(task=\"binary\", average='macro', num_classes=2)  \n        self.accuracy = Accuracy(task=\"binary\", average='macro', num_classes=2)\n        #self.dice = Dice(num_classes=2, average='macro') \n        \n        \n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = self.CEL(logits, y)\n        \n        # Compute metrics\n        train_precision = self.precision(logits.softmax(dim=1)[:, 1, ...], y)\n        train_recall = self.recall(logits.softmax(dim=1)[:, 1, ...], y)\n        train_accuracy = self.accuracy(logits.softmax(dim=1)[:, 1, ...], y)\n        #train_dice = self.dice(torch.squeeze(logits.softmax(dim=1)[:, 1, ...], dim=1), y)\n\n        # Logging metrics\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_precision', train_precision, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_recall', train_recall, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('train_accuracy', train_accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        #self.log('train_dice', train_dice, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        \n        return loss\n    \n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.model(x)\n        loss = self.CEL(logits, y)\n\n        # Compute metrics\n        val_precision = self.precision(logits.softmax(dim=1)[:, 1, ...], y)\n        val_recall = self.recall(logits.softmax(dim=1)[:, 1, ...], y)\n        val_accuracy = self.accuracy(logits.softmax(dim=1)[:, 1, ...], y)\n        #val_dice = self.dice(logits.softmax(dim=1)[:, 1, ...], y)\n\n        # Logging metrics\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_precision', val_precision, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_recall', val_recall, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_accuracy', val_accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        #self.log('val_dice', val_dice, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        \n        \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.model(x)\n        loss = self.CEL(logits, y)\n\n        # Compute metrics\n        test_precision = self.precision(logits.softmax(dim=1)[:, 1, ...], y)\n        test_recall = self.recall(logits.softmax(dim=1)[:, 1, ...], y)\n        test_accuracy = self.accuracy(logits.softmax(dim=1)[:, 1, ...], y)\n        #test_dice = self.dice(logits.softmax(dim=1)[:, 1, ...], y) # Compute Dice for test set\n\n\n        # Logging metrics\n        self.log('test_loss', loss, prog_bar=True, logger=True)\n        self.log('test_precision', test_precision, prog_bar=True, logger=True)\n        self.log('test_recall', test_recall, prog_bar=True, logger=True)\n        self.log('test_accuracy', test_accuracy, prog_bar=True, logger=True)\n        #self.log('test_dice', test_dice, prog_bar=True, logger=True)\n\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        return optimizer\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:52:21.586712Z","iopub.execute_input":"2023-07-17T09:52:21.589035Z","iopub.status.idle":"2023-07-17T09:52:21.609011Z","shell.execute_reply.started":"2023-07-17T09:52:21.589001Z","shell.execute_reply":"2023-07-17T09:52:21.607971Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Create early-stopping and checkpoint callback function ","metadata":{}},{"cell_type":"code","source":"early_stop_callback = EarlyStopping(\n   monitor='val_loss',\n   patience=3,\n   verbose=False,\n   mode='min'\n)\n\ncheckpoint_callback = ModelCheckpoint(\n    monitor='val_loss',\n    dirpath='model/',\n    filename='best-checkpoint',\n    save_top_k=1,\n    mode='min')","metadata":{"execution":{"iopub.status.busy":"2023-07-17T09:28:32.623042Z","iopub.execute_input":"2023-07-17T09:28:32.623420Z","iopub.status.idle":"2023-07-17T09:28:32.629511Z","shell.execute_reply.started":"2023-07-17T09:28:32.623391Z","shell.execute_reply":"2023-07-17T09:28:32.628523Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Training..!","metadata":{}},{"cell_type":"code","source":"model = Contrails_U_Net(learning_rate=5e-4)\ndm = ContrailsDataModule(batch_size=16, bands=[\"band_08.npy\"], timestep=4)\n\n# create the csv logger for results\n# Instantiate CSV logger\ncsv_logger = CSVLogger('logs/', name='csv_log')\n\n\ntrainer = Trainer(\n    accelerator=\"auto\",\n    devices = \"auto\",\n    max_epochs=8,\n    callbacks=[TQDMProgressBar(refresh_rate=20)], # optional: early_stop_callback, checkpoint_callback\n    logger=csv_logger,\n    log_every_n_steps =100,\n)\ntrainer.fit(model, dm)","metadata":{"execution":{"iopub.status.busy":"2023-07-17T12:51:25.670379Z","iopub.execute_input":"2023-07-17T12:51:25.670755Z","iopub.status.idle":"2023-07-17T15:38:03.236656Z","shell.execute_reply.started":"2023-07-17T12:51:25.670726Z","shell.execute_reply":"2023-07-17T15:38:03.235711Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\nINFO: \n  | Name      | Type             | Params\n-----------------------------------------------\n0 | model     | UNet2            | 17.3 M\n1 | CEL       | CrossEntropyLoss | 0     \n2 | precision | BinaryPrecision  | 0     \n3 | recall    | BinaryRecall     | 0     \n4 | accuracy  | BinaryAccuracy   | 0     \n-----------------------------------------------\n17.3 M    Trainable params\n0         Non-trainable params\n17.3 M    Total params\n69.065    Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4a4028e701499a823a47f5a15f617f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"markdown","source":"## Plot training progress","metadata":{}},{"cell_type":"code","source":"# Read data from CSV file\nlog_data = pd.read_csv('logs/csv_log/version_0/metrics.csv')\nlog_data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_data[log_data['train_precision'].notna()]['train_precision']","metadata":{"execution":{"iopub.status.busy":"2023-07-16T06:48:37.194577Z","iopub.status.idle":"2023-07-16T06:48:37.195725Z","shell.execute_reply.started":"2023-07-16T06:48:37.195469Z","shell.execute_reply":"2023-07-16T06:48:37.195492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data from CSV file\nlog_data = pd.read_csv('logs/csv_log/version_0/metrics.csv')\n\n# Plot training loss\nplt.figure(figsize=(10,6))\nplt.plot(log_data[log_data['train_precision'].notna()]['step'], log_data[log_data['train_precision'].notna()]['train_precision'], label='Training Loss')\n#plt.plot(log_data['step'], log_data['val_loss_step'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Training Steps')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T06:48:37.197249Z","iopub.status.idle":"2023-07-16T06:48:37.198036Z","shell.execute_reply.started":"2023-07-16T06:48:37.197788Z","shell.execute_reply":"2023-07-16T06:48:37.197811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training precision\nplt.figure(figsize=(10,6))\nplt.plot(log_data['step'], log_data['train_precision'], label='Training Precision')\nplt.plot(log_data['step'], log_data['val_precision'], label='Validation Precision')\nplt.title('Training and Validation Precision')\nplt.xlabel('Training Steps')\nplt.ylabel('Precision')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-16T06:48:37.199492Z","iopub.status.idle":"2023-07-16T06:48:37.200272Z","shell.execute_reply.started":"2023-07-16T06:48:37.199997Z","shell.execute_reply":"2023-07-16T06:48:37.200020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testset Prediction","metadata":{}},{"cell_type":"code","source":"# After training\ntrainer.test()\n\n# Or load a pre-trained model and test\nmodel = Contrails_U_Net.load_from_checkpoint('path_to_checkpoint.ckpt')\ntrainer = Trainer()\ntrainer.test(model, test_dataloaders=dm.test_dataloader())","metadata":{"execution":{"iopub.status.busy":"2023-07-16T06:48:37.201700Z","iopub.status.idle":"2023-07-16T06:48:37.202479Z","shell.execute_reply.started":"2023-07-16T06:48:37.202227Z","shell.execute_reply":"2023-07-16T06:48:37.202250Z"},"trusted":true},"execution_count":null,"outputs":[]}]}